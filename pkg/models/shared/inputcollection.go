// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

type InputCollectionConnections struct {
	// Select a Destination.
	Output string `json:"output"`
	// Select Pipeline or Pack. Optional.
	Pipeline *string `json:"pipeline,omitempty"`
}

func (o *InputCollectionConnections) GetOutput() string {
	if o == nil {
		return ""
	}
	return o.Output
}

func (o *InputCollectionConnections) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

type InputCollectionMetadata struct {
	// Field name
	Name string `json:"name"`
	// JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)
	Value string `json:"value"`
}

func (o *InputCollectionMetadata) GetName() string {
	if o == nil {
		return ""
	}
	return o.Name
}

func (o *InputCollectionMetadata) GetValue() string {
	if o == nil {
		return ""
	}
	return o.Value
}

// InputCollectionPqCompression - Codec to use to compress the persisted data.
type InputCollectionPqCompression string

const (
	InputCollectionPqCompressionNone InputCollectionPqCompression = "none"
	InputCollectionPqCompressionGzip InputCollectionPqCompression = "gzip"
)

func (e InputCollectionPqCompression) ToPointer() *InputCollectionPqCompression {
	return &e
}

func (e *InputCollectionPqCompression) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "none":
		fallthrough
	case "gzip":
		*e = InputCollectionPqCompression(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectionPqCompression: %v", v)
	}
}

// InputCollectionPqMode - With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
type InputCollectionPqMode string

const (
	InputCollectionPqModeSmart  InputCollectionPqMode = "smart"
	InputCollectionPqModeAlways InputCollectionPqMode = "always"
)

func (e InputCollectionPqMode) ToPointer() *InputCollectionPqMode {
	return &e
}

func (e *InputCollectionPqMode) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "smart":
		fallthrough
	case "always":
		*e = InputCollectionPqMode(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectionPqMode: %v", v)
	}
}

type InputCollectionPq struct {
	// The number of events to send downstream before committing that Stream has read them.
	CommitFrequency *int64 `json:"commitFrequency,omitempty"`
	// Codec to use to compress the persisted data.
	Compress *InputCollectionPqCompression `json:"compress,omitempty"`
	// The maximum number of events to hold in memory before writing the events to disk.
	MaxBufferSize *int64 `json:"maxBufferSize,omitempty"`
	// The maximum size to store in each queue file before closing and optionally compressing (KB, MB, etc.).
	MaxFileSize *string `json:"maxFileSize,omitempty"`
	// The maximum amount of disk space the queue is allowed to consume. Once reached, the system stops queueing and applies the fallback Queue-full behavior. Enter a numeral with units of KB, MB, etc.
	MaxSize *string `json:"maxSize,omitempty"`
	// With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine.
	Mode *InputCollectionPqMode `json:"mode,omitempty"`
	// The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>.
	Path *string `json:"path,omitempty"`
}

func (o *InputCollectionPq) GetCommitFrequency() *int64 {
	if o == nil {
		return nil
	}
	return o.CommitFrequency
}

func (o *InputCollectionPq) GetCompress() *InputCollectionPqCompression {
	if o == nil {
		return nil
	}
	return o.Compress
}

func (o *InputCollectionPq) GetMaxBufferSize() *int64 {
	if o == nil {
		return nil
	}
	return o.MaxBufferSize
}

func (o *InputCollectionPq) GetMaxFileSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxFileSize
}

func (o *InputCollectionPq) GetMaxSize() *string {
	if o == nil {
		return nil
	}
	return o.MaxSize
}

func (o *InputCollectionPq) GetMode() *InputCollectionPqMode {
	if o == nil {
		return nil
	}
	return o.Mode
}

func (o *InputCollectionPq) GetPath() *string {
	if o == nil {
		return nil
	}
	return o.Path
}

type InputCollectionPreprocess struct {
	// Arguments
	Args []string `json:"args,omitempty"`
	// Command to feed the data through (via stdin) and process its output (stdout)
	Command *string `json:"command,omitempty"`
	// Enable Custom Command
	Disabled bool `json:"disabled"`
}

func (o *InputCollectionPreprocess) GetArgs() []string {
	if o == nil {
		return nil
	}
	return o.Args
}

func (o *InputCollectionPreprocess) GetCommand() *string {
	if o == nil {
		return nil
	}
	return o.Command
}

func (o *InputCollectionPreprocess) GetDisabled() bool {
	if o == nil {
		return false
	}
	return o.Disabled
}

type InputCollectionType string

const (
	InputCollectionTypeCollection InputCollectionType = "collection"
)

func (e InputCollectionType) ToPointer() *InputCollectionType {
	return &e
}

func (e *InputCollectionType) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "collection":
		*e = InputCollectionType(v)
		return nil
	default:
		return fmt.Errorf("invalid value for InputCollectionType: %v", v)
	}
}

type InputCollection struct {
	// A list of event breaking rulesets that will be applied, in order, to the input data stream.
	BreakerRulesets []string `json:"breakerRulesets,omitempty"`
	// Direct connections to Destinations, optionally via a Pipeline or a Pack.
	Connections []InputCollectionConnections `json:"connections,omitempty"`
	// Enable/disable this input
	Disabled *bool `json:"disabled,omitempty"`
	// Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere.
	Environment *string `json:"environment,omitempty"`
	// Unique ID for this input
	ID string `json:"id"`
	// Fields to add to events from this input.
	Metadata []InputCollectionMetadata `json:"metadata,omitempty"`
	// Destination to send results to.
	Output *string `json:"output,omitempty"`
	// Pipeline to process results.
	Pipeline *string            `json:"pipeline,omitempty"`
	Pq       *InputCollectionPq `json:"pq,omitempty"`
	// For details on Persistent Queues, see: [https://docs.cribl.io/stream/persistent-queues](https://docs.cribl.io/stream/persistent-queues)
	PqEnabled  *bool                      `json:"pqEnabled,omitempty"`
	Preprocess *InputCollectionPreprocess `json:"preprocess,omitempty"`
	// If set to Yes, events will be sent to normal routing and event processing. Set to No if you want to select a specific Pipeline/Destination combination.
	SendToRoutes *bool `json:"sendToRoutes,omitempty"`
	// The amount of time (in milliseconds) the Event Breaker will wait for new data to be sent to a specific channel, before flushing the data stream out, as-is, to the Pipelines.
	StaleChannelFlushMs *int64 `json:"staleChannelFlushMs,omitempty"`
	// Add tags for filtering and grouping in @{product}.
	Streamtags []string `json:"streamtags,omitempty"`
	// Rate (in bytes per second) to throttle while writing to an output. Also takes values with multiple-byte units, such as KB, MB, GB, etc. (E.g., 42 MB.) Default value of 0 specifies no throttling.
	ThrottleRatePerSec *string             `json:"throttleRatePerSec,omitempty"`
	Type               InputCollectionType `json:"type"`
}

func (o *InputCollection) GetBreakerRulesets() []string {
	if o == nil {
		return nil
	}
	return o.BreakerRulesets
}

func (o *InputCollection) GetConnections() []InputCollectionConnections {
	if o == nil {
		return nil
	}
	return o.Connections
}

func (o *InputCollection) GetDisabled() *bool {
	if o == nil {
		return nil
	}
	return o.Disabled
}

func (o *InputCollection) GetEnvironment() *string {
	if o == nil {
		return nil
	}
	return o.Environment
}

func (o *InputCollection) GetID() string {
	if o == nil {
		return ""
	}
	return o.ID
}

func (o *InputCollection) GetMetadata() []InputCollectionMetadata {
	if o == nil {
		return nil
	}
	return o.Metadata
}

func (o *InputCollection) GetOutput() *string {
	if o == nil {
		return nil
	}
	return o.Output
}

func (o *InputCollection) GetPipeline() *string {
	if o == nil {
		return nil
	}
	return o.Pipeline
}

func (o *InputCollection) GetPq() *InputCollectionPq {
	if o == nil {
		return nil
	}
	return o.Pq
}

func (o *InputCollection) GetPqEnabled() *bool {
	if o == nil {
		return nil
	}
	return o.PqEnabled
}

func (o *InputCollection) GetPreprocess() *InputCollectionPreprocess {
	if o == nil {
		return nil
	}
	return o.Preprocess
}

func (o *InputCollection) GetSendToRoutes() *bool {
	if o == nil {
		return nil
	}
	return o.SendToRoutes
}

func (o *InputCollection) GetStaleChannelFlushMs() *int64 {
	if o == nil {
		return nil
	}
	return o.StaleChannelFlushMs
}

func (o *InputCollection) GetStreamtags() []string {
	if o == nil {
		return nil
	}
	return o.Streamtags
}

func (o *InputCollection) GetThrottleRatePerSec() *string {
	if o == nil {
		return nil
	}
	return o.ThrottleRatePerSec
}

func (o *InputCollection) GetType() InputCollectionType {
	if o == nil {
		return InputCollectionType("")
	}
	return o.Type
}
